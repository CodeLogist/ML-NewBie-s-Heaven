{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment-Analysis-RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FinoqdSheE7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEUzUiAdfAXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('reviews.txt','r') as f:\n",
        "  reviews=f.read()\n",
        "with open('labels.txt','r') as f:\n",
        "  labels=f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxpaKsDYftig",
        "colab_type": "code",
        "outputId": "53c31355-2744-49a2-8c54-4ce2986f38c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "reviews[:2000]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   \\nstory of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it  s singers . unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting . even those from the era should be turned off . the cryptic dialogue would make shakespeare seem easy to a third grader . on a technical level it  s better than you might think with some good cinematography by future great vilmos zsigmond . future stars sally kirkland and frederic forrest can be seen briefly .  \\nhomelessness  or houselessness as george carlin stated  has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school  work  or vote for the matter . most people think of the homeless as just a lost cause while worrying about things such as racism  the war on iraq  pressuring kids to succeed  technology  the elections  inflation  or worrying if they  ll be next to end up on the streets .  br    br   but what if y'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWv7YcllCisG",
        "colab_type": "text"
      },
      "source": [
        "#Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0rKJchjf6Q5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from string import punctuation\n",
        "all_text=''.join([c for c in reviews if c not in punctuation])\n",
        "reviews = all_text.split('\\n')\n",
        "\n",
        "all_text = ' '.join(reviews)\n",
        "words = all_text.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tWaxE3VB1pa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_text[:2000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNRSxxh0CsUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words[:100]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrziW56lCt4H",
        "colab_type": "text"
      },
      "source": [
        "##Encoding the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE9Uf1teCwZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "counts = Counter(words)\n",
        "vocab = sorted(counts, key=counts.get, reverse=True)\n",
        "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
        "\n",
        "reviews_ints = []\n",
        "for each in reviews:\n",
        "    reviews_ints.append([vocab_to_int[word] for word in each.split()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrKpeIKoC1c3",
        "colab_type": "text"
      },
      "source": [
        "##Encoding the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_UG3DAoC32n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = labels.split('\\n')\n",
        "labels = np.array([1 if each == 'positive' else 0 for each in labels])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Goq3op_FDGj3",
        "colab_type": "text"
      },
      "source": [
        "##Removing Zero length reviews and their labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZyuQfDZC7Pl",
        "colab_type": "code",
        "outputId": "61f991c8-b441-4552-caee-8879e1e80fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "review_lens = Counter([len(x) for x in reviews_ints])\n",
        "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
        "print(\"Maximum review length: {}\".format(max(review_lens)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zero-length reviews: 0\n",
            "Maximum review length: 2514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDiyshA8DAoH",
        "colab_type": "code",
        "outputId": "efb7f035-9b46-4e93-fc23-23dbf439972a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "non_zero_idx = [ii for ii, review in enumerate(reviews_ints) if len(review) != 0]\n",
        "len(non_zero_idx)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DI-QjqIDD0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_ints = [reviews_ints[ii] for ii in non_zero_idx]\n",
        "labels = np.array([labels[ii] for ii in non_zero_idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHWOBbqdDQEJ",
        "colab_type": "text"
      },
      "source": [
        "##Padding reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw9yiQjhDTsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_len = 200\n",
        "features = np.zeros((len(reviews_ints), seq_len), dtype=int)\n",
        "for i, row in enumerate(reviews_ints):\n",
        "    features[i, -len(row):] = np.array(row)[:seq_len]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwt-2pp8DYcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features[:10,:100]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnTFebh4DcZ3",
        "colab_type": "text"
      },
      "source": [
        "##Training,Validation,Test Split\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzX2UM0nGRl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ePCdDI2DjYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split_frac=0.8\n",
        "split_idx=int(len(features)*split_frac)\n",
        "train_idx=np.random.choice(len(features),split_idx,replace=0)\n",
        "# val_idx=[x for x in range(25000) if x not in train_idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7Rjdkq1GgFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_val=[features[x] for x in train_idx],[features[x] for x in range(25000) if x not in train_idx]\n",
        "y_train,y_val=[labels[x] for x in train_idx],[labels[x] for x in range(25000) if x not in train_idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LrbXpN3KxpI",
        "colab_type": "code",
        "outputId": "7f11b5c2-ee6a-48cc-bdb4-559c94fdc1c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(x_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go-QVnBSHinU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_idx=int(len(x_val)*0.5)\n",
        "x_test,y_test=x_val[:test_idx],y_val[:test_idx]\n",
        "x_val,y_val=x_val[test_idx:],y_val[test_idx:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYGiAaWVIKTH",
        "colab_type": "code",
        "outputId": "4f12437f-ee94-4956-b196-9fcf333d1440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "x_train,y_train,x_val,y_val,x_test,y_test=np.array(x_train),np.array(y_train),np.array(x_val),np.array(y_val),np.array(x_test),np.array(y_test)\n",
        "print(\"\\t\\t\\tFeature Shapes:\")\n",
        "print(\"Train set: \\t\\t{}\".format(x_train.shape), \n",
        "      \"\\nValidation set: \\t{}\".format(x_val.shape),\n",
        "      \"\\nTest set: \\t\\t{}\".format(x_test.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tFeature Shapes:\n",
            "Train set: \t\t(20000, 200) \n",
            "Validation set: \t(2500, 200) \n",
            "Test set: \t\t(2500, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fc1fiQeIVWb",
        "colab_type": "text"
      },
      "source": [
        "#Building Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo7rKbHuL0Sp",
        "colab_type": "text"
      },
      "source": [
        "##Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0lbWO1SIYDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm_size=256\n",
        "lstm_layers=1\n",
        "batch_size=500\n",
        "learning_rate=1e-3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QiupBfdMY6I",
        "colab_type": "text"
      },
      "source": [
        "##Defining inputs, labels and placeholders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISZg3ESWMP0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_words=len(vocab_to_int)+1\n",
        "graph=tf.Graph()\n",
        "with graph.as_default():\n",
        "  inputs_=tf.placeholder(tf.int32,[None,None],name='inputs')\n",
        "  labels_=tf.placeholder(tf.int32,[None,None],name='labels')\n",
        "  keep_prob=tf.placeholder(tf.float32,name='keep_prob')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVei1D60NmZv",
        "colab_type": "text"
      },
      "source": [
        "##Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S467mdpNorA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size=300\n",
        "with graph.as_default():\n",
        "  embedding=tf.Variable(tf.random_uniform((n_words,embed_size),+1,-1))\n",
        "  embed=tf.nn.embedding_lookup(embedding,inputs_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYjnAlGNPEwo",
        "colab_type": "text"
      },
      "source": [
        "##LSTM cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XCIGAMbOtU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with graph.as_default():\n",
        "  lstm=tf.nn.rnn_cell.LSTMCell(lstm_size)\n",
        "  dropout=tf.nn.rnn_cell.DropoutWrapper(lstm,output_keep_prob=keep_prob)\n",
        "  lstm_layer=tf.nn.rnn_cell.MultiRNNCell([dropout]*lstm_layers)\n",
        "  initial_state=lstm_layer.zero_state(batch_size,tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HwKvg-4RYRg",
        "colab_type": "text"
      },
      "source": [
        "##RNN forward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vKK76kORLvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with graph.as_default():\n",
        "  outputs,final_state=tf.nn.dynamic_rnn(lstm_layer,embed,initial_state=initial_state)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcxsNZqnTE3R",
        "colab_type": "text"
      },
      "source": [
        "##Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBwu02cRTHvg",
        "colab_type": "code",
        "outputId": "d18d875d-1da6-4440-dacb-09f2b74da990",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "with graph.as_default():\n",
        "  predictions=tf.contrib.layers.fully_connected(outputs[:,-1],1,activation_fn=tf.sigmoid)\n",
        "  cost=tf.losses.mean_squared_error(labels_,predictions)\n",
        "  optimizer=tf.train.AdamOptimizer(learning_rate).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0706 12:44:13.757879 140686651438976 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0706 12:44:14.058392 140686651438976 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4AEnAKDUEXx",
        "colab_type": "text"
      },
      "source": [
        "##Validation Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJVn0b8vUUcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with graph.as_default():\n",
        "  correct_pred=tf.equal(tf.cast(tf.round(predictions),tf.int32),labels_)\n",
        "  accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdKrwz2DUzCO",
        "colab_type": "text"
      },
      "source": [
        "##Batching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo1LBosiU3GQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(x,y,batch_size=100):\n",
        "  n_batches=len(x)//batch_size\n",
        "  x,y=x[:n_batches*batch_size],y[:n_batches*batch_size]\n",
        "  for i in range(0,len(x),batch_size):\n",
        "    yield x[i:i+batch_size],y[i:i+batch_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rztNuDjVilC",
        "colab_type": "text"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qshYhNtmVkrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=10\n",
        "with graph.as_default():\n",
        "  saver=tf.train.Saver()\n",
        "  \n",
        "with tf.Session(graph=graph) as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  \n",
        "  iteration=1\n",
        "  for e in range(epochs):\n",
        "    state=sess.run(initial_state)\n",
        "    for i,(x,y) in enumerate(get_batches(x_train,y_train,batch_size),1):\n",
        "      feed={inputs_:x,\n",
        "           labels_:y[:,None],\n",
        "           keep_prob:0.5,\n",
        "           initial_state:state}\n",
        "      loss,state,_ = sess.run([cost,final_state,optimizer],feed_dict=feed)\n",
        "      if iteration%5==0:\n",
        "        print(\"Epoch: {}/{}\".format(e, epochs),\n",
        "                      \"Iteration: {}\".format(iteration),\n",
        "                      \"Train loss: {:.3f}\".format(loss))\n",
        "      if iteration%25==0:\n",
        "        val_acc=[]\n",
        "        val_state=sess.run(lstm_layer.zero_state(batch_size,tf.float32))\n",
        "        for x,y in get_batches(x_val,y_val,batch_size):\n",
        "          feed={inputs_:x,\n",
        "               labels_:y[:,None],\n",
        "               keep_prob:1,\n",
        "               initial_state:val_state}\n",
        "          batch_acc,val_state=sess.run([accuracy,final_state],feed_dict=feed)\n",
        "          val_acc.append(batch_acc)\n",
        "        print(\"Val acc: {:.3f}\".format(np.mean(val_acc)))\n",
        "      iteration +=1\n",
        "  saver.save(sess, \"checkpoints/sentiment.ckpt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bGD0hs3Ygq6",
        "colab_type": "text"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwIyCyiCYosA",
        "colab_type": "code",
        "outputId": "6914817d-fa75-41f6-b8d5-44e0778be4f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_acc = []\n",
        "with tf.Session(graph=graph) as sess:\n",
        "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
        "    test_state = sess.run(lstm_layer.zero_state(batch_size, tf.float32))\n",
        "    for ii, (x, y) in enumerate(get_batches(x_test, y_test, batch_size), 1):\n",
        "        feed = {inputs_: x,\n",
        "                labels_: y[:, None],\n",
        "                keep_prob: 1,\n",
        "                initial_state: test_state}\n",
        "        batch_acc, test_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
        "        test_acc.append(batch_acc)\n",
        "    print(\"Test accuracy: {:.3f}\".format(np.mean(test_acc)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.838\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}